# -*- coding: utf-8 -*-
# web_ui.py
"""
Streamlit æ³•å¾‹åŠ©æ‰‹ä¸»ç•Œé¢æ¨¡å—
åŒ…å«Webç•Œé¢äº¤äº’å’Œä¸»æµç¨‹æ§åˆ¶
"""

import re
import time
import streamlit as st
from pathlib import Path
from llama_index.core import get_response_synthesizer, PromptTemplate

from core.config import Config
from core.models import ModelInitializer
from core.data_processor import DataProcessor
from core.vector_store import VectorStoreManager


def disable_streamlit_watcher():
    """Patch Streamlit to disable file watcher"""
    def _on_script_changed(_):
        return
    from streamlit import runtime
    runtime.get_instance()._on_script_changed = _on_script_changed

class WebInterface:
    """æ³•å¾‹åŠ©æ‰‹Webç•Œé¢ä¸»ç±»"""

    def __init__(self):
        # åˆå§‹åŒ–åŸºç¡€é…ç½®
        self._init_page_config()

        # åˆå§‹åŒ–ç»„ä»¶
        self.embed_model, self.llm, self.reranker = ModelInitializer.init_models()

        # åŠ è½½æˆ–åˆ›å»ºç´¢å¼•
        if not Path(Config.VECTOR_DB_DIR).exists():
            raw_data = DataProcessor.load_and_validate_json(Config.DATA_DIR)
            nodes = DataProcessor.create_nodes(raw_data)
        else:
            nodes = None

        self.vector_mgr = VectorStoreManager()
        self.index = self.vector_mgr.init_index(nodes)

        # åˆå§‹åŒ–å¼•æ“
        self.retriever = self.index.as_retriever(
            similarity_top_k=Config.TOP_K,
            vector_store_query_mode="hybrid",
            alpha=0.5
        )
        self.query_engine = self.index.as_query_engine(
            similarity_top_k=Config.TOP_K,
            node_postprocessors=[self.reranker]
        )

        # å“åº”åˆæˆå™¨
        self.response_template = PromptTemplate(Config.QA_TEMPLATE)
        self.response_synthesizer = get_response_synthesizer(
            text_qa_template=self.response_template,
            verbose=True)

    def _init_page_config(self):
        """åˆå§‹åŒ–é¡µé¢é…ç½®"""
        st.set_page_config(
            page_title="æ™ºèƒ½åŠ³åŠ¨æ³•å’¨è¯¢åŠ©æ‰‹",
            page_icon="âš–ï¸",
            layout="centered",
            initial_sidebar_state="auto"
        )

    # ================== ç•Œé¢ç»„ä»¶ ==================
    def _init_chat_interface(self):
        if "messages" not in st.session_state:
            st.session_state.messages = []

        for msg in st.session_state.messages:
            role = msg["role"]
            content = msg.get("cleaned", msg["content"])  # ä¼˜å…ˆä½¿ç”¨æ¸…ç†åçš„å†…å®¹

            with st.chat_message(role):
                st.markdown(content)

                # å¦‚æœæ˜¯åŠ©æ‰‹æ¶ˆæ¯ä¸”åŒ…å«æ€ç»´é“¾
                if role == "assistant" and msg.get("think"):
                    with st.expander("ğŸ“ æ¨¡å‹æ€è€ƒè¿‡ç¨‹ï¼ˆå†å²å¯¹è¯ï¼‰"):
                        for think_content in msg["think"]:
                            st.markdown(f'<span style="color: #808080">{think_content.strip()}</span>',
                                        unsafe_allow_html=True)

                # å¦‚æœæ˜¯åŠ©æ‰‹æ¶ˆæ¯ä¸”æœ‰å‚è€ƒä¾æ®ï¼ˆéœ€è¦ä¿æŒåŸæœ‰å‚è€ƒä¾æ®é€»è¾‘ï¼‰
                if role == "assistant" and "reference_nodes" in msg:
                    self._show_reference_details(msg["reference_nodes"])

    def _show_reference_details(self, nodes):
        """æ˜¾ç¤ºæ³•å¾‹æ¡æ–‡å‚è€ƒè¯¦æƒ…"""
        with st.expander("æŸ¥çœ‹æ”¯æŒä¾æ®"):
            for idx, node in enumerate(nodes[:3], 1):  # æ˜¾ç¤ºå‰3ä¸ªç›¸å…³ç»“æœ
                meta = node.node.metadata
                st.markdown(f"**[{idx}] {meta['full_title']}**")
                st.caption(f"æ¥æºæ–‡ä»¶ï¼š{meta['source_file']} | æ³•å¾‹åç§°ï¼š{meta['law_name']}")
                st.markdown(f"ç›¸å…³åº¦ï¼š`{node.score:.4f}`")
                st.info(node.node.text)

    def run(self):
        """ä¸»è¿è¡Œå…¥å£"""
        # ç¦ç”¨ Streamlit æ–‡ä»¶çƒ­é‡è½½
        disable_streamlit_watcher()
        st.title("âš–ï¸ æ™ºèƒ½åŠ³åŠ¨æ³•å’¨è¯¢åŠ©æ‰‹")
        st.markdown("æ¬¢è¿ä½¿ç”¨åŠ³åŠ¨æ³•æ™ºèƒ½å’¨è¯¢ç³»ç»Ÿï¼Œè¯·è¾“å…¥æ‚¨çš„é—®é¢˜ï¼Œæˆ‘ä»¬å°†åŸºäºæœ€æ–°åŠ³åŠ¨æ³•å¾‹æ³•è§„ä¸ºæ‚¨è§£ç­”ã€‚")

        # åˆå§‹åŒ–ä¼šè¯çŠ¶æ€
        if "history" not in st.session_state:
            st.session_state.history = []

        # èŠå¤©ç•Œé¢
        self._init_chat_interface()

        if prompt := st.chat_input("è¯·è¾“å…¥åŠ³åŠ¨æ³•ç›¸å…³é—®é¢˜"):
            # æ·»åŠ ç”¨æˆ·æ¶ˆæ¯åˆ°å†å²
            st.session_state.messages.append({"role": "user", "content": prompt})
            with st.chat_message("user"):
                st.markdown(prompt)

            # å¤„ç†æŸ¥è¯¢
            with st.spinner("æ­£åœ¨åˆ†æé—®é¢˜..."):
                start_time = time.time()

                # æ£€ç´¢æµç¨‹
                initial_nodes = self.retriever.retrieve(prompt)
                reranked_nodes = self.reranker.postprocess_nodes(initial_nodes, query_str=prompt)

                # è¿‡æ»¤èŠ‚ç‚¹
                MIN_RERANK_SCORE = 0.4
                filtered_nodes = [node for node in reranked_nodes if node.score > MIN_RERANK_SCORE]

                if not filtered_nodes:
                    response_text = "âš ï¸ æœªæ‰¾åˆ°ç›¸å…³æ³•å¾‹æ¡æ–‡ï¼Œè¯·å°è¯•è°ƒæ•´é—®é¢˜æè¿°æˆ–å’¨è¯¢ä¸“ä¸šå¾‹å¸ˆã€‚"
                else:
                    # ç”Ÿæˆå›ç­”
                    response = self.response_synthesizer.synthesize(prompt, nodes=filtered_nodes)
                    response_text = response.response

                # æ˜¾ç¤ºå›ç­”
                with st.chat_message("assistant"):
                    # æå–æ€ç»´é“¾å†…å®¹å¹¶æ¸…ç†å“åº”æ–‡æœ¬
                    think_contents = re.findall(r'<think>(.*?)</think>', response_text, re.DOTALL)
                    cleaned_response = re.sub(r'<think>.*?</think>', '', response_text, flags=re.DOTALL).strip()

                    # æ˜¾ç¤ºæ¸…ç†åçš„å›ç­”
                    st.markdown(cleaned_response)

                    # å¦‚æœæœ‰æ€ç»´é“¾å†…å®¹åˆ™æ˜¾ç¤º
                    if think_contents:
                        with st.expander("ğŸ“ æ¨¡å‹æ€è€ƒè¿‡ç¨‹ï¼ˆç‚¹å‡»å±•å¼€ï¼‰"):
                            for content in think_contents:
                                st.markdown(f'<span style="color: #808080">{content.strip()}</span>',
                                            unsafe_allow_html=True)

                    # æ˜¾ç¤ºå‚è€ƒä¾æ®ï¼ˆä¿æŒåŸæœ‰é€»è¾‘ï¼‰
                    self._show_reference_details(filtered_nodes[:3])

                # æ·»åŠ åŠ©æ‰‹æ¶ˆæ¯åˆ°å†å²ï¼ˆéœ€è¦å­˜å‚¨åŸå§‹å“åº”ï¼‰
                st.session_state.messages.append({
                    "role": "assistant",
                    "content": response_text,  # ä¿ç•™åŸå§‹å“åº”
                    "cleaned": cleaned_response,  # å­˜å‚¨æ¸…ç†åçš„æ–‡æœ¬
                    "think": think_contents  # å­˜å‚¨æ€ç»´é“¾å†…å®¹
                })

# è¿è¡Œå…¥å£
if __name__ == "__main__":
    web_app = WebInterface()
    web_app.run()